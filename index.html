<!DOCTYPE html>
<html lang="en">

    <head>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<title> K-Means Visualiser </title>
	<link rel="stylesheet" href="screen.css" type="text/css" />
	<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0,maximum-scale=1.0,user-scalable=no">
</head>
<body class="en">
<div class = "header" id="myHeader">
	<header>
		<h1 class="title"> K-Means Clustering Algorithm </h1>
		</br>
		<h2 class="navbar"><a href="#information">Information</a> | <a href="#wrap">Visualisation</a></h2>
	</header>
</div>
	<div id="wrap">
		<div class="wrapped">
			<article>
				<div class="entry-body">

					<section>
						<div class ="input">
							<fieldset>
								<div><label for="N">N (the number of node):</label><input type="number" id="N" min="2" max="1000" value="100"></div>
							</fieldset>

							<fieldset>
								<div><label for="K">K (the number of cluster):</label><input type="number" id="K" min="2" max="50" value="5"></div>
							</fieldset>

							<fieldset>
								<div><label for="C">Draw Centroids: </label><input type="checkbox" id="centroids" onchange="javascript:centroids(this);"></div>
							</fieldset> 

							<fieldset>
							<div><input type="checkbox" name="manual" onchange="javascript: manual(this);"/>Place Starting Positions Manually</div> 
							</fieldset>

							<div><button id="reset">New Selection</button></div>
						</div>

						<div>
							<button id="step">Step</button> 
							<button id="restart" disabled>Restart</button> 
							<button id="run">Run</button></div>
						</div> 
			
						<div id="kmeans">
							<div>
							<svg></svg>
							</div>
						</div> 
						<!-- 
						<div id="tutorial">
						<h3>K Means Clustering Algorithm Visualisation </h3>
						<h6>This short tutorial will walk you through all of the features of this application.</h6>
						<p>If you want to dive right in, feel free to press the "Skip Tutorial" button below. Otherwise, press "Next"!</p>
						<button id="nextButton" type="button">Next</button>
						<button id="previousButton" type="button">Previous</button>
						<button id="skipButton" type="button">Skip Tutorial</button>
						</div>-->

					<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.6/d3.js" charset="utf-8"></script>
					<script src="k-means.js"></script>

				</div>
			</article>
		</div>
	</div>
	<div id="information">
		<h1 class = "informationHeader">Information</h1>

		<h2 class="subheading">Overview of K-Means</h2>
			<ul> 
				<li> K Means is one of the simplest yet powerful unsupervised machine learning clustering algorithms.  </li>
				<li> It is used to find similarities and relationships amongst the set of data that is used and creates clusters. </li>
			</ul>


		<h2 class="subheading">How does it work</h2>
		<img src= "images/elbowMethod.png" alt="Elbow Method" class="elbow">
			</br>
			<p> It works by creating clusters from a data set. This process involves dividing the entire data into groups based on the patterns in the data set. It is an unsupervised learning algorithm, which means there is no fixed target variable as we don’t have targets to predict. We need to look at the data and make observations and create different clusters. </p>
			<br>
			<p>One way to find the optimal number of clusters include using the elbow method. This is when you plot a line chart including the number of clusters (value of k) and the data. Then you must join the points. When there is a rapid drop in values, the line will create an elbow shape. </p>
			
			<br>
			<p>A target number k is then formed. This will be the number of centroids you need, and it will act as the imaginary locations representing the centre of cluster. The algorithm will then allocate every data point to the nearest cluster, trying to keep centroids as small as possible. </p>
			<br>
			<b>The algorithm will halt when:</b>
			<ul> 
				<li> Centroids stabilise meaning no change in value due to successful clustering. </li>
				<li> The number of iterations declared has been achieved. </li>
			</ul>

		<h2 class="subheading">Steps</h2>
		<img src= "images/stages1-5.png" alt="Steps" class="stages">
			<ol>
				<li> Choose number of clusters (k) using elbow method </li>
				<li> Select k random points from the data as centroids </li>
				<li> Assign all the points to the closest cluster  </li>
				<li> Recompute the centroids of newly formed clusters </li>
				<li> Repeat 3 and 4 until centroids are stable in value and the number of iterations defined are achieved </li>
			</ol>
			

		<h2 class="subheading">Why is it used</h2>
			<ul> 
				<li> <b>Customer segmentation </b> – helps divide customers into groups based on common characteristics </li> 
				<li> <b> Document clustering </b> – will put documents into groups depending on similarities </li> 
				<li> <b> Image segmentation </b> – will cluster images with similar pixels </li> 
				<li> <b> Recommendation engines </b> – makes recommendations depending on likes. E.g. songs </li> 
			</ul>

		<h2 class="subheading">Assumptions on how K Means Works</h2>
		<ul> 
			<li> Clusters being spherical helps with separating clusters when the data is being analysed and clusters are being formed.</li>
			<li> Clusters being a similar size helps deciding the boundaries of the clusters and helps calculating the number of data points. </li>
		</ul>

		<h2 class="subheading">Definitions</h2>
			<ul>
				<li> <b> K Value: </b> the number of centroids you need in a dataset. </li>
				<li> <b> Elbow Method: </b> heuristic used to determine the number of clusters in a data set. </li>
				<li> <b> Clustering: </b> A collection of data points that are accumulated together as they have similarities. </li>
				<li> <b> Centroids: </b> location representing centre of cluster. </li>
			</ul>

		<table>
			<tr>
					<th>Advantages</th>
					<th>Disadvantages</th>
				</tr>
				<tr>
					<td>Scales to large data sets. </td>
					<td>Choosing k manually may take a long time. </td>
				</tr>
				<tr>
					<td>Simple to implement. </td>
					<td>Being dependent on initial values such the k value. </td>
				</tr>
				<tr>
					<td>Adapts to new examples. </td>
					<td>Clustering outliers may lead to them getting their own cluster instead of it being ignored. </td>
				</tr>
				<tr>
					<td>Generalizes clusters of different shapes and sizes. </td>
					<td>Clustering data of varying sizes and density can cause issues. </td>
				</tr>
		</table>
	</div>
	<footer>
		Copyright (C): Haris Nazir & Rozerin Baran 2020
	</footer>
</body>
</html>
